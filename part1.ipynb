{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Neural Network Project - Part 2 - summer 2024\n","### Mohammad Hossein Najafi - 97103938\n","---"]},{"cell_type":"markdown","metadata":{},"source":["### Libraries"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:05:18.560296Z","iopub.status.busy":"2024-07-01T07:05:18.559557Z","iopub.status.idle":"2024-07-01T07:05:18.566892Z","shell.execute_reply":"2024-07-01T07:05:18.565952Z","shell.execute_reply.started":"2024-07-01T07:05:18.560260Z"},"id":"e5lBVb3wsgUT","trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import torchvision\n","import torch.nn as nn # use nn functions like sigmoid, ReLu, softmax\n","import torchvision.transforms as transforms # use for transformerin on data\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset,DataLoader\n","import torchvision.models as models\n","import os\n","from PIL import Image\n","import io\n","import zipfile\n","from torch.utils.data import DataLoader, random_split\n","import torch.nn.functional as F\n","import time\n","from scipy.spatial.distance import pdist, squareform\n","from sklearn.decomposition import PCA\n","import json\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:05:19.719381Z","iopub.status.busy":"2024-07-01T07:05:19.719031Z","iopub.status.idle":"2024-07-01T07:05:32.138873Z","shell.execute_reply":"2024-07-01T07:05:32.137719Z","shell.execute_reply.started":"2024-07-01T07:05:19.719355Z"},"id":"5Wfh0GwzPHgU","outputId":"fb0d2819-409a-4717-8e73-5efffb0b644b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["import io\n","! pip install gdown"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:05:32.142068Z","iopub.status.busy":"2024-07-01T07:05:32.141277Z","iopub.status.idle":"2024-07-01T07:05:34.835560Z","shell.execute_reply":"2024-07-01T07:05:34.834382Z","shell.execute_reply.started":"2024-07-01T07:05:32.142026Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1hAfkobN0YBk2D2fqhhRht2yKmF1nNwWz\n","To: /kaggle/working/kaggle.json\n","100%|█████████████████████████████████████████| 64.0/64.0 [00:00<00:00, 354kB/s]\n"]}],"source":["! gdown 1hAfkobN0YBk2D2fqhhRht2yKmF1nNwWz"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T01:53:08.331165Z","iopub.status.busy":"2024-07-01T01:53:08.330462Z","iopub.status.idle":"2024-07-01T01:53:11.170748Z","shell.execute_reply":"2024-07-01T01:53:11.169598Z","shell.execute_reply.started":"2024-07-01T01:53:08.331129Z"},"trusted":true},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!mv kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T01:53:13.336907Z","iopub.status.busy":"2024-07-01T01:53:13.336548Z","iopub.status.idle":"2024-07-01T01:54:30.752453Z","shell.execute_reply":"2024-07-01T01:54:30.751201Z","shell.execute_reply.started":"2024-07-01T01:53:13.336868Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset URL: https://www.kaggle.com/datasets/danielbacioiu/tig-aluminium-5083\n","License(s): CC-BY-SA-4.0\n","Downloading tig-aluminium-5083.zip to /kaggle/working\n","100%|██████████████████████████████████████▉| 11.2G/11.2G [01:15<00:00, 172MB/s]\n","100%|███████████████████████████████████████| 11.2G/11.2G [01:15<00:00, 159MB/s]\n"]}],"source":["!kaggle datasets download -d danielbacioiu/tig-aluminium-5083"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:05:37.968966Z","iopub.status.busy":"2024-07-01T07:05:37.968496Z","iopub.status.idle":"2024-07-01T07:05:40.081914Z","shell.execute_reply":"2024-07-01T07:05:40.081076Z","shell.execute_reply.started":"2024-07-01T07:05:37.968924Z"},"trusted":true},"outputs":[],"source":["class smdataset(Dataset):\n","    def __init__(self, zip_file_path, folder_name, json_file_path, transform=None):\n","        self.zip_file = zipfile.ZipFile(zip_file_path, 'r')\n","        self.folder_name = folder_name.rstrip('/') + '/'\n","        self.file_list = [name for name in self.zip_file.namelist() if name.startswith(self.folder_name) and name.endswith('.png')]\n","        self.transform = transform\n","\n","        # Load labels from JSON file\n","        with self.zip_file.open(json_file_path) as json_file:\n","            self.labels_dict = json.load(json_file)\n","\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        try:\n","            with self.zip_file.open(self.file_list[idx]) as file:\n","                image = Image.open(io.BytesIO(file.read()))\n","                if self.transform:\n","                    image = self.transform(image)\n","            \n","            # Extract the relevant part of the filename for lookup\n","            file_name = self.file_list[idx].replace(self.folder_name, '')  # Remove folder_name prefix\n","\n","          \n","            \n","            # Get the label for the current file\n","            label = self.labels_dict.get(file_name, -1) \n","\n","          \n","\n","            return image, label\n","        except Exception as e:\n","            return None, None\n","\n","# Define the necessary transforms (if any)\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","])\n","\n","# Update these paths based on the output from the above listing\n","train_json_path = 'al5083/al5083/train/train.json'  # Correct path from listing\n","test_json_path = 'al5083/al5083/test/test.json'    # Correct path from listing\n","\n","# Create the datasets\n","train_dataset = smdataset(\n","    zip_file_path='/kaggle/working/tig-aluminium-5083.zip',\n","    folder_name='al5083/train',\n","    json_file_path=train_json_path,\n","    transform=transform\n",")\n","\n","test_dataset = smdataset(\n","    zip_file_path='/kaggle/working/tig-aluminium-5083.zip',\n","    folder_name='al5083/test',\n","    json_file_path=test_json_path,\n","    transform=transform\n",")\n","\n"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:05:40.509556Z","iopub.status.busy":"2024-07-01T07:05:40.508878Z","iopub.status.idle":"2024-07-01T07:05:40.547202Z","shell.execute_reply":"2024-07-01T07:05:40.546095Z","shell.execute_reply.started":"2024-07-01T07:05:40.509522Z"},"id":"IEOQkH9nw2d2","trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n","\n","test_dataloader = DataLoader(test_dataset,batch_size=32,shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:08:44.635388Z","iopub.status.busy":"2024-07-01T07:08:44.634841Z","iopub.status.idle":"2024-07-01T07:08:44.654768Z","shell.execute_reply":"2024-07-01T07:08:44.653753Z","shell.execute_reply.started":"2024-07-01T07:08:44.635347Z"},"trusted":true},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, num_classes=6):\n","        super(CNN, self).__init__()\n","        # Define the convolutional layers\n","        self.conv1 = nn.Conv2d(1, 128, kernel_size=5, padding=0, stride=1)\n","        self.bn1 = nn.BatchNorm2d(128)\n","        \n","        self.pool1 = nn.AvgPool2d(kernel_size=5, stride=2)\n","        \n","        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=0, stride=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        \n","        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=0, stride=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.conv4_1 = nn.Conv2d(128, 96, kernel_size=3, padding=0, stride=1)\n","        self.bn4_1 = nn.BatchNorm2d(96)\n","        self.conv4_2 = nn.Conv2d(96, 96, kernel_size=3, padding=0, stride=1)\n","        self.bn4_2 = nn.BatchNorm2d(96)\n","        \n","        self.conv5_1 = nn.Conv2d(96, 96, kernel_size=3, padding=0, stride=1)\n","        self.bn5_1 = nn.BatchNorm2d(96)\n","        self.conv5_2 = nn.Conv2d(96, 96, kernel_size=3, padding=0, stride=1)\n","        self.bn5_2 = nn.BatchNorm2d(96)\n","        \n","        self.pool2 = nn.AvgPool2d(kernel_size=5, stride=2)\n","        \n","        self.dropout = nn.Dropout(0.5)\n","        \n","        # Define the fully connected layers\n","        self.fc1 = nn.Linear(96 * 54 * 54, 128)  # Correct input size based on output of conv layers\n","        self.dropout_fc1 = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        # Apply convolutional layers followed by pooling\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = self.pool1(x)\n","        \n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        \n","        x = F.relu(self.bn4_1(self.conv4_1(x)))\n","        x = F.relu(self.bn4_2(self.conv4_2(x)))\n","        \n","        x = F.relu(self.bn5_1(self.conv5_1(x)))\n","        x = F.relu(self.bn5_2(self.conv5_2(x)))\n","        \n","        x = self.pool2(x)\n","        \n","        x = self.dropout(x)\n","        \n","        # Flatten the output from the conv layers to feed into the fully connected layer\n","        x = x.view(x.size(0), -1)  # Flatten\n","        \n","        # Fully connected layers\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout_fc1(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:08:45.800627Z","iopub.status.busy":"2024-07-01T07:08:45.799926Z","iopub.status.idle":"2024-07-01T07:08:46.221097Z","shell.execute_reply":"2024-07-01T07:08:46.220183Z","shell.execute_reply.started":"2024-07-01T07:08:45.800591Z"},"id":"GKTPk1eF0FK8","outputId":"0228bcb6-1864-408d-b960-361739440510","trusted":true},"outputs":[{"data":{"text/plain":["CNN(\n","  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n","  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool1): AvgPool2d(kernel_size=5, stride=2, padding=0)\n","  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4_1): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (bn4_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (bn4_2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv5_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (bn5_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv5_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (bn5_2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool2): AvgPool2d(kernel_size=5, stride=2, padding=0)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=279936, out_features=128, bias=True)\n","  (dropout_fc1): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",")"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["model = CNN()\n","device = \"cuda\"\n","model.to(device)"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:08:49.119837Z","iopub.status.busy":"2024-07-01T07:08:49.119463Z","iopub.status.idle":"2024-07-01T07:08:49.126806Z","shell.execute_reply":"2024-07-01T07:08:49.125907Z","shell.execute_reply.started":"2024-07-01T07:08:49.119806Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["conv1.weight: torch.Size([128, 1, 5, 5]) (3200 parameters)\n","conv1.bias: torch.Size([128]) (128 parameters)\n","bn1.weight: torch.Size([128]) (128 parameters)\n","bn1.bias: torch.Size([128]) (128 parameters)\n","conv2.weight: torch.Size([128, 128, 3, 3]) (147456 parameters)\n","conv2.bias: torch.Size([128]) (128 parameters)\n","bn2.weight: torch.Size([128]) (128 parameters)\n","bn2.bias: torch.Size([128]) (128 parameters)\n","conv3.weight: torch.Size([128, 128, 3, 3]) (147456 parameters)\n","conv3.bias: torch.Size([128]) (128 parameters)\n","bn3.weight: torch.Size([128]) (128 parameters)\n","bn3.bias: torch.Size([128]) (128 parameters)\n","conv4_1.weight: torch.Size([96, 128, 3, 3]) (110592 parameters)\n","conv4_1.bias: torch.Size([96]) (96 parameters)\n","bn4_1.weight: torch.Size([96]) (96 parameters)\n","bn4_1.bias: torch.Size([96]) (96 parameters)\n","conv4_2.weight: torch.Size([96, 96, 3, 3]) (82944 parameters)\n","conv4_2.bias: torch.Size([96]) (96 parameters)\n","bn4_2.weight: torch.Size([96]) (96 parameters)\n","bn4_2.bias: torch.Size([96]) (96 parameters)\n","conv5_1.weight: torch.Size([96, 96, 3, 3]) (82944 parameters)\n","conv5_1.bias: torch.Size([96]) (96 parameters)\n","bn5_1.weight: torch.Size([96]) (96 parameters)\n","bn5_1.bias: torch.Size([96]) (96 parameters)\n","conv5_2.weight: torch.Size([96, 96, 3, 3]) (82944 parameters)\n","conv5_2.bias: torch.Size([96]) (96 parameters)\n","bn5_2.weight: torch.Size([96]) (96 parameters)\n","bn5_2.bias: torch.Size([96]) (96 parameters)\n","fc1.weight: torch.Size([128, 279936]) (35831808 parameters)\n","fc1.bias: torch.Size([128]) (128 parameters)\n","fc2.weight: torch.Size([6, 128]) (768 parameters)\n","fc2.bias: torch.Size([6]) (6 parameters)\n","\n","Total number of parameters: 36492550\n"]}],"source":["total_params = 0\n","for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(f\"{name}: {param.data.shape} ({param.numel()} parameters)\")\n","        total_params += param.numel()\n","\n","print(f\"\\nTotal number of parameters: {total_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Training and Testing\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lossfn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=1e-2, weight_decay=1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/10: 848batch [10:48,  1.31batch/s, loss=0.144]                      \n","Epoch 2/10: 848batch [10:48,  1.31batch/s, loss=0.112]                      \n","Epoch 3/10: 848batch [10:50,  1.30batch/s, loss=0.0884]                      \n","Epoch 4/10: 848batch [10:54,  1.30batch/s, loss=0.071]                       \n","Epoch 5/10: 848batch [10:51,  1.30batch/s, loss=0.0543]                      \n","Epoch 6/10: 848batch [10:46,  1.31batch/s, loss=0.0543]                      \n","Epoch 7/10: 848batch [10:45,  1.31batch/s, loss=0.0443]                      \n","Epoch 8/10: 848batch [10:45,  1.31batch/s, loss=0.0375]                      \n","Epoch 9/10: 848batch [10:45,  1.31batch/s, loss=0.0336]                      \n","Epoch 10/10: 848batch [10:46,  1.31batch/s, loss=0.0317]                      \n"]}],"source":["num_epoch = 10\n","\n","for epoch in range(num_epoch):\n","    # Training phase\n","    model.train()\n","    train_loss = 0.0\n","    train_batches = len(train_dataloader)\n","    \n","    with tqdm(total=train_batches, desc=f'Epoch {epoch+1}/{num_epoch}', unit='batch') as pbar:\n","        for i, (images, labels) in enumerate(train_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = lossfn(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","            \n","            \n","\n","            if i % 16 == 0:\n","                pbar.set_postfix({'loss': train_loss / (i + 1)})\n","                pbar.update(16)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing Batches: 100%|██████████| 206/206 [01:28<00:00,  2.33it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 58.01%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["#Testing\n","correct = 0\n","total = 0\n","\n","for images, labels in tqdm(test_dataloader, desc=\"Processing Batches\"):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    prediction = torch.argmax(outputs, dim=1)\n","    correct += (prediction == labels).sum().item()\n","    total += labels.size(0)\n","\n","accuracy = correct / total * 100\n","print(f'Accuracy: {accuracy:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["### FPS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing Batches: 100%|██████████| 206/206 [01:51<00:00,  1.85it/s]"]},{"name":"stdout","output_type":"stream","text":["FPS: 59.21\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import time\n","\n","correct = 0\n","total = 0\n","\n","# Measure the inference time\n","start_time = time.time()\n","\n","for images, labels in tqdm(test_dataloader, desc=\"Processing Batches\"):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(images)\n","        prediction = torch.argmax(outputs, dim=1)\n","        correct += (prediction == labels).sum().item()\n","        total += labels.size(0)\n","\n","end_time = time.time()\n","\n","# Calculate FPS\n","total_time = end_time - start_time\n","num_frames = total\n","fps = num_frames / total_time\n","print(f\"FPS: {fps:.2f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
